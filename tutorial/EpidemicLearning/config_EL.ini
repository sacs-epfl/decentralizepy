[DATASET]
dataset_package = decentralizepy.datasets.CIFAR10
dataset_class = CIFAR10
model_class = LeNet
; provide directory containing "cifar-10-batches-py" folder | Pre-download recommended
; New download does not work with multiple processes | Crashes the first time, just retry
train_dir = ../../eval/data/
test_dir = ../../eval/data/
; python list of fractions below
sizes = 
random_seed = 90
partition_niid = dirichlet
alpha = 0.1 ; alpha (dirichlet parameter)

[OPTIMIZER_PARAMS]
optimizer_package = torch.optim
optimizer_class = SGD
lr = 0.05 ; gamma

[TRAIN_PARAMS]
training_package = decentralizepy.training.Training
training_class = Training
rounds = 10 ; r
full_epochs = False
batch_size = 5 ; b
shuffle = True
loss_package = torch.nn
loss_class = CrossEntropyLoss

[COMMUNICATION]
comm_package = decentralizepy.communication.TCP
comm_class = TCP
addresses_filepath = ip.json

[SHARING]
sharing_package = decentralizepy.sharing.PlainAverageSharing ; Does not use Metropolis-Hastings
sharing_class = PlainAverageSharing
compress = False

[NODE]
graph_degree = 7 ; s (number of neighbors in EL-Oracle and number of random neighbors picked to send message to in EL-Local)